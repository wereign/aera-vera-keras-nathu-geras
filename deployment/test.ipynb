{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"./iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species',axis=1)\n",
    "y = iris['species']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(y)  # converts the labels to one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 2s 54ms/step - loss: 1.2230 - accuracy: 0.3500 - val_loss: 1.3813 - val_accuracy: 0.2667\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2059 - accuracy: 0.3500 - val_loss: 1.3614 - val_accuracy: 0.2667\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1891 - accuracy: 0.3500 - val_loss: 1.3424 - val_accuracy: 0.2667\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1727 - accuracy: 0.3500 - val_loss: 1.3240 - val_accuracy: 0.2667\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1581 - accuracy: 0.3500 - val_loss: 1.3061 - val_accuracy: 0.2667\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1425 - accuracy: 0.3500 - val_loss: 1.2893 - val_accuracy: 0.2667\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1288 - accuracy: 0.3500 - val_loss: 1.2732 - val_accuracy: 0.2667\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1158 - accuracy: 0.3500 - val_loss: 1.2579 - val_accuracy: 0.2667\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1034 - accuracy: 0.3500 - val_loss: 1.2434 - val_accuracy: 0.2667\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0908 - accuracy: 0.3500 - val_loss: 1.2300 - val_accuracy: 0.2667\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0807 - accuracy: 0.3500 - val_loss: 1.2168 - val_accuracy: 0.2667\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0704 - accuracy: 0.3500 - val_loss: 1.2043 - val_accuracy: 0.2667\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0607 - accuracy: 0.3583 - val_loss: 1.1923 - val_accuracy: 0.3333\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0514 - accuracy: 0.3667 - val_loss: 1.1809 - val_accuracy: 0.3333\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0423 - accuracy: 0.3833 - val_loss: 1.1701 - val_accuracy: 0.3667\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0350 - accuracy: 0.3917 - val_loss: 1.1595 - val_accuracy: 0.3667\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0267 - accuracy: 0.4333 - val_loss: 1.1496 - val_accuracy: 0.3667\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0185 - accuracy: 0.4750 - val_loss: 1.1406 - val_accuracy: 0.3667\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0122 - accuracy: 0.5417 - val_loss: 1.1317 - val_accuracy: 0.4000\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0060 - accuracy: 0.5750 - val_loss: 1.1231 - val_accuracy: 0.4000\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9994 - accuracy: 0.5917 - val_loss: 1.1150 - val_accuracy: 0.4000\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9937 - accuracy: 0.6000 - val_loss: 1.1072 - val_accuracy: 0.4667\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9877 - accuracy: 0.6333 - val_loss: 1.1001 - val_accuracy: 0.5000\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9827 - accuracy: 0.6583 - val_loss: 1.0931 - val_accuracy: 0.5667\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9775 - accuracy: 0.6583 - val_loss: 1.0864 - val_accuracy: 0.5667\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9729 - accuracy: 0.6750 - val_loss: 1.0801 - val_accuracy: 0.6000\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9683 - accuracy: 0.6833 - val_loss: 1.0741 - val_accuracy: 0.6000\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9638 - accuracy: 0.6833 - val_loss: 1.0685 - val_accuracy: 0.6000\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9602 - accuracy: 0.6833 - val_loss: 1.0628 - val_accuracy: 0.6000\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9562 - accuracy: 0.6833 - val_loss: 1.0574 - val_accuracy: 0.6000\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9521 - accuracy: 0.6833 - val_loss: 1.0524 - val_accuracy: 0.6000\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9491 - accuracy: 0.6833 - val_loss: 1.0473 - val_accuracy: 0.6000\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9451 - accuracy: 0.6833 - val_loss: 1.0427 - val_accuracy: 0.6000\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9418 - accuracy: 0.6833 - val_loss: 1.0383 - val_accuracy: 0.6000\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9387 - accuracy: 0.6833 - val_loss: 1.0340 - val_accuracy: 0.6000\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9359 - accuracy: 0.6833 - val_loss: 1.0298 - val_accuracy: 0.6000\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9327 - accuracy: 0.6833 - val_loss: 1.0258 - val_accuracy: 0.6000\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9300 - accuracy: 0.6833 - val_loss: 1.0220 - val_accuracy: 0.6000\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9277 - accuracy: 0.6833 - val_loss: 1.0181 - val_accuracy: 0.6000\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9248 - accuracy: 0.6833 - val_loss: 1.0145 - val_accuracy: 0.6000\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9225 - accuracy: 0.6833 - val_loss: 1.0111 - val_accuracy: 0.6000\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9201 - accuracy: 0.6833 - val_loss: 1.0078 - val_accuracy: 0.6000\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9177 - accuracy: 0.6833 - val_loss: 1.0047 - val_accuracy: 0.6000\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9156 - accuracy: 0.6833 - val_loss: 1.0016 - val_accuracy: 0.6000\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9134 - accuracy: 0.6833 - val_loss: 0.9986 - val_accuracy: 0.6000\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9112 - accuracy: 0.6833 - val_loss: 0.9958 - val_accuracy: 0.6000\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9093 - accuracy: 0.6833 - val_loss: 0.9930 - val_accuracy: 0.6000\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9072 - accuracy: 0.6833 - val_loss: 0.9903 - val_accuracy: 0.6000\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9053 - accuracy: 0.6833 - val_loss: 0.9876 - val_accuracy: 0.6000\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9037 - accuracy: 0.6833 - val_loss: 0.9849 - val_accuracy: 0.6000\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9016 - accuracy: 0.6833 - val_loss: 0.9825 - val_accuracy: 0.6000\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8998 - accuracy: 0.6833 - val_loss: 0.9803 - val_accuracy: 0.6000\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8980 - accuracy: 0.6833 - val_loss: 0.9780 - val_accuracy: 0.6000\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8963 - accuracy: 0.6833 - val_loss: 0.9757 - val_accuracy: 0.6000\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8945 - accuracy: 0.6833 - val_loss: 0.9734 - val_accuracy: 0.6000\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8928 - accuracy: 0.6833 - val_loss: 0.9710 - val_accuracy: 0.6000\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8911 - accuracy: 0.6833 - val_loss: 0.9686 - val_accuracy: 0.6000\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8896 - accuracy: 0.6833 - val_loss: 0.9663 - val_accuracy: 0.6000\n",
      "Epoch 59/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8877 - accuracy: 0.6833 - val_loss: 0.9642 - val_accuracy: 0.6000\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8859 - accuracy: 0.6833 - val_loss: 0.9622 - val_accuracy: 0.6000\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8843 - accuracy: 0.6833 - val_loss: 0.9601 - val_accuracy: 0.6000\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8827 - accuracy: 0.6833 - val_loss: 0.9581 - val_accuracy: 0.6000\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8812 - accuracy: 0.6833 - val_loss: 0.9560 - val_accuracy: 0.6000\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8795 - accuracy: 0.6833 - val_loss: 0.9540 - val_accuracy: 0.6000\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8778 - accuracy: 0.6833 - val_loss: 0.9522 - val_accuracy: 0.6000\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8764 - accuracy: 0.6833 - val_loss: 0.9502 - val_accuracy: 0.6000\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8747 - accuracy: 0.6833 - val_loss: 0.9483 - val_accuracy: 0.6000\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8732 - accuracy: 0.6833 - val_loss: 0.9465 - val_accuracy: 0.6000\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8716 - accuracy: 0.6833 - val_loss: 0.9447 - val_accuracy: 0.6000\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8702 - accuracy: 0.6833 - val_loss: 0.9430 - val_accuracy: 0.6000\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8687 - accuracy: 0.6833 - val_loss: 0.9412 - val_accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8672 - accuracy: 0.6833 - val_loss: 0.9396 - val_accuracy: 0.6000\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8657 - accuracy: 0.6833 - val_loss: 0.9379 - val_accuracy: 0.6000\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8642 - accuracy: 0.6833 - val_loss: 0.9361 - val_accuracy: 0.6000\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8627 - accuracy: 0.6833 - val_loss: 0.9346 - val_accuracy: 0.6000\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8611 - accuracy: 0.6833 - val_loss: 0.9329 - val_accuracy: 0.6000\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8596 - accuracy: 0.6833 - val_loss: 0.9312 - val_accuracy: 0.6000\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8581 - accuracy: 0.6833 - val_loss: 0.9297 - val_accuracy: 0.6000\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8567 - accuracy: 0.6833 - val_loss: 0.9281 - val_accuracy: 0.6000\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8552 - accuracy: 0.6833 - val_loss: 0.9266 - val_accuracy: 0.6000\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8538 - accuracy: 0.6833 - val_loss: 0.9252 - val_accuracy: 0.6000\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8524 - accuracy: 0.6833 - val_loss: 0.9236 - val_accuracy: 0.6000\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8509 - accuracy: 0.6833 - val_loss: 0.9221 - val_accuracy: 0.6000\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8494 - accuracy: 0.6833 - val_loss: 0.9206 - val_accuracy: 0.6000\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8480 - accuracy: 0.6833 - val_loss: 0.9193 - val_accuracy: 0.6000\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8466 - accuracy: 0.6833 - val_loss: 0.9177 - val_accuracy: 0.6000\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8452 - accuracy: 0.6833 - val_loss: 0.9162 - val_accuracy: 0.6000\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8437 - accuracy: 0.6833 - val_loss: 0.9147 - val_accuracy: 0.6000\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8423 - accuracy: 0.6833 - val_loss: 0.9132 - val_accuracy: 0.6000\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8409 - accuracy: 0.6833 - val_loss: 0.9118 - val_accuracy: 0.6000\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8394 - accuracy: 0.6833 - val_loss: 0.9104 - val_accuracy: 0.6000\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8380 - accuracy: 0.6833 - val_loss: 0.9089 - val_accuracy: 0.6000\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8366 - accuracy: 0.6833 - val_loss: 0.9073 - val_accuracy: 0.6000\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8351 - accuracy: 0.6833 - val_loss: 0.9058 - val_accuracy: 0.6000\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8336 - accuracy: 0.6833 - val_loss: 0.9043 - val_accuracy: 0.6000\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8322 - accuracy: 0.6833 - val_loss: 0.9028 - val_accuracy: 0.6000\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8307 - accuracy: 0.6833 - val_loss: 0.9014 - val_accuracy: 0.6000\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8293 - accuracy: 0.6833 - val_loss: 0.8999 - val_accuracy: 0.6000\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8278 - accuracy: 0.6833 - val_loss: 0.8983 - val_accuracy: 0.6000\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8264 - accuracy: 0.6833 - val_loss: 0.8968 - val_accuracy: 0.6000\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8250 - accuracy: 0.6833 - val_loss: 0.8951 - val_accuracy: 0.6000\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8235 - accuracy: 0.6833 - val_loss: 0.8937 - val_accuracy: 0.6000\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8220 - accuracy: 0.6833 - val_loss: 0.8921 - val_accuracy: 0.6000\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8206 - accuracy: 0.6833 - val_loss: 0.8905 - val_accuracy: 0.6000\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8191 - accuracy: 0.6833 - val_loss: 0.8890 - val_accuracy: 0.6000\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8176 - accuracy: 0.6833 - val_loss: 0.8875 - val_accuracy: 0.6000\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8162 - accuracy: 0.6833 - val_loss: 0.8860 - val_accuracy: 0.6000\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8147 - accuracy: 0.6833 - val_loss: 0.8845 - val_accuracy: 0.6000\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8133 - accuracy: 0.6833 - val_loss: 0.8830 - val_accuracy: 0.6000\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8118 - accuracy: 0.6833 - val_loss: 0.8816 - val_accuracy: 0.6000\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8104 - accuracy: 0.6833 - val_loss: 0.8801 - val_accuracy: 0.6000\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8089 - accuracy: 0.6833 - val_loss: 0.8786 - val_accuracy: 0.6000\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8074 - accuracy: 0.6833 - val_loss: 0.8771 - val_accuracy: 0.6000\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8060 - accuracy: 0.6833 - val_loss: 0.8756 - val_accuracy: 0.6000\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8045 - accuracy: 0.6833 - val_loss: 0.8741 - val_accuracy: 0.6000\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8030 - accuracy: 0.6833 - val_loss: 0.8726 - val_accuracy: 0.6000\n",
      "Epoch 117/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8016 - accuracy: 0.6833 - val_loss: 0.8711 - val_accuracy: 0.6000\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8001 - accuracy: 0.6833 - val_loss: 0.8696 - val_accuracy: 0.6000\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7987 - accuracy: 0.6833 - val_loss: 0.8681 - val_accuracy: 0.6000\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7971 - accuracy: 0.6833 - val_loss: 0.8666 - val_accuracy: 0.6000\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7957 - accuracy: 0.6833 - val_loss: 0.8652 - val_accuracy: 0.6000\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7942 - accuracy: 0.6833 - val_loss: 0.8637 - val_accuracy: 0.6000\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7928 - accuracy: 0.6833 - val_loss: 0.8623 - val_accuracy: 0.6000\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7912 - accuracy: 0.6833 - val_loss: 0.8607 - val_accuracy: 0.6000\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7898 - accuracy: 0.6833 - val_loss: 0.8591 - val_accuracy: 0.6000\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7883 - accuracy: 0.6833 - val_loss: 0.8576 - val_accuracy: 0.6000\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7868 - accuracy: 0.6833 - val_loss: 0.8560 - val_accuracy: 0.6000\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7853 - accuracy: 0.6833 - val_loss: 0.8546 - val_accuracy: 0.6000\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7839 - accuracy: 0.6833 - val_loss: 0.8531 - val_accuracy: 0.6000\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7824 - accuracy: 0.6833 - val_loss: 0.8515 - val_accuracy: 0.6000\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7809 - accuracy: 0.6833 - val_loss: 0.8499 - val_accuracy: 0.6000\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7794 - accuracy: 0.6833 - val_loss: 0.8484 - val_accuracy: 0.6000\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7779 - accuracy: 0.6917 - val_loss: 0.8469 - val_accuracy: 0.6000\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7765 - accuracy: 0.6917 - val_loss: 0.8454 - val_accuracy: 0.6000\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7750 - accuracy: 0.6917 - val_loss: 0.8438 - val_accuracy: 0.6333\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7735 - accuracy: 0.6917 - val_loss: 0.8422 - val_accuracy: 0.6333\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7721 - accuracy: 0.6917 - val_loss: 0.8406 - val_accuracy: 0.6333\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7705 - accuracy: 0.6917 - val_loss: 0.8390 - val_accuracy: 0.6333\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7691 - accuracy: 0.6917 - val_loss: 0.8374 - val_accuracy: 0.6333\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7676 - accuracy: 0.6917 - val_loss: 0.8358 - val_accuracy: 0.6333\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7661 - accuracy: 0.6917 - val_loss: 0.8343 - val_accuracy: 0.6333\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7647 - accuracy: 0.6917 - val_loss: 0.8326 - val_accuracy: 0.6333\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7633 - accuracy: 0.6917 - val_loss: 0.8310 - val_accuracy: 0.6333\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7618 - accuracy: 0.6917 - val_loss: 0.8294 - val_accuracy: 0.6333\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7603 - accuracy: 0.6917 - val_loss: 0.8278 - val_accuracy: 0.6333\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7589 - accuracy: 0.6917 - val_loss: 0.8262 - val_accuracy: 0.6333\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7574 - accuracy: 0.7000 - val_loss: 0.8247 - val_accuracy: 0.6333\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7560 - accuracy: 0.7000 - val_loss: 0.8230 - val_accuracy: 0.6333\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7545 - accuracy: 0.7000 - val_loss: 0.8214 - val_accuracy: 0.6333\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7531 - accuracy: 0.7000 - val_loss: 0.8198 - val_accuracy: 0.6333\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7516 - accuracy: 0.7000 - val_loss: 0.8182 - val_accuracy: 0.6333\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7501 - accuracy: 0.7000 - val_loss: 0.8166 - val_accuracy: 0.6333\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7487 - accuracy: 0.7000 - val_loss: 0.8151 - val_accuracy: 0.6333\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7473 - accuracy: 0.7000 - val_loss: 0.8137 - val_accuracy: 0.6333\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7458 - accuracy: 0.7000 - val_loss: 0.8122 - val_accuracy: 0.6333\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7444 - accuracy: 0.7000 - val_loss: 0.8106 - val_accuracy: 0.6333\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7429 - accuracy: 0.7000 - val_loss: 0.8091 - val_accuracy: 0.6333\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7415 - accuracy: 0.7000 - val_loss: 0.8075 - val_accuracy: 0.6333\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7400 - accuracy: 0.7000 - val_loss: 0.8060 - val_accuracy: 0.6333\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7386 - accuracy: 0.7083 - val_loss: 0.8045 - val_accuracy: 0.6333\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7372 - accuracy: 0.7083 - val_loss: 0.8029 - val_accuracy: 0.6333\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7358 - accuracy: 0.7083 - val_loss: 0.8014 - val_accuracy: 0.6333\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7343 - accuracy: 0.7083 - val_loss: 0.7997 - val_accuracy: 0.6333\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7329 - accuracy: 0.7083 - val_loss: 0.7982 - val_accuracy: 0.6333\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7315 - accuracy: 0.7083 - val_loss: 0.7967 - val_accuracy: 0.6333\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7300 - accuracy: 0.7083 - val_loss: 0.7952 - val_accuracy: 0.6333\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7285 - accuracy: 0.7083 - val_loss: 0.7936 - val_accuracy: 0.6333\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7271 - accuracy: 0.7083 - val_loss: 0.7921 - val_accuracy: 0.6333\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7257 - accuracy: 0.7083 - val_loss: 0.7906 - val_accuracy: 0.6333\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7243 - accuracy: 0.7083 - val_loss: 0.7892 - val_accuracy: 0.6333\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7228 - accuracy: 0.7083 - val_loss: 0.7876 - val_accuracy: 0.6333\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7215 - accuracy: 0.7083 - val_loss: 0.7860 - val_accuracy: 0.6333\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7201 - accuracy: 0.7083 - val_loss: 0.7844 - val_accuracy: 0.6333\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7186 - accuracy: 0.7083 - val_loss: 0.7830 - val_accuracy: 0.6333\n",
      "Epoch 175/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7172 - accuracy: 0.7083 - val_loss: 0.7816 - val_accuracy: 0.6333\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7158 - accuracy: 0.7083 - val_loss: 0.7800 - val_accuracy: 0.6333\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7144 - accuracy: 0.7083 - val_loss: 0.7784 - val_accuracy: 0.6333\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7130 - accuracy: 0.7083 - val_loss: 0.7768 - val_accuracy: 0.6333\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7116 - accuracy: 0.7083 - val_loss: 0.7753 - val_accuracy: 0.6333\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7102 - accuracy: 0.7083 - val_loss: 0.7738 - val_accuracy: 0.6333\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7088 - accuracy: 0.7083 - val_loss: 0.7723 - val_accuracy: 0.6333\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7075 - accuracy: 0.7083 - val_loss: 0.7707 - val_accuracy: 0.6333\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7060 - accuracy: 0.7083 - val_loss: 0.7693 - val_accuracy: 0.6333\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7046 - accuracy: 0.7083 - val_loss: 0.7678 - val_accuracy: 0.6333\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7032 - accuracy: 0.7083 - val_loss: 0.7662 - val_accuracy: 0.6333\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7018 - accuracy: 0.7083 - val_loss: 0.7646 - val_accuracy: 0.6333\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7004 - accuracy: 0.7083 - val_loss: 0.7630 - val_accuracy: 0.6333\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6992 - accuracy: 0.7250 - val_loss: 0.7613 - val_accuracy: 0.6333\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6977 - accuracy: 0.7250 - val_loss: 0.7597 - val_accuracy: 0.6333\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6963 - accuracy: 0.7250 - val_loss: 0.7582 - val_accuracy: 0.6333\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6949 - accuracy: 0.7250 - val_loss: 0.7567 - val_accuracy: 0.6333\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6936 - accuracy: 0.7250 - val_loss: 0.7552 - val_accuracy: 0.6333\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6922 - accuracy: 0.7250 - val_loss: 0.7537 - val_accuracy: 0.6333\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.7250 - val_loss: 0.7522 - val_accuracy: 0.6333\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.7250 - val_loss: 0.7506 - val_accuracy: 0.6333\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6881 - accuracy: 0.7250 - val_loss: 0.7491 - val_accuracy: 0.6333\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6867 - accuracy: 0.7250 - val_loss: 0.7476 - val_accuracy: 0.6333\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6854 - accuracy: 0.7250 - val_loss: 0.7461 - val_accuracy: 0.6333\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6841 - accuracy: 0.7250 - val_loss: 0.7445 - val_accuracy: 0.6333\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6827 - accuracy: 0.7250 - val_loss: 0.7430 - val_accuracy: 0.6333\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6813 - accuracy: 0.7250 - val_loss: 0.7415 - val_accuracy: 0.6333\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6800 - accuracy: 0.7250 - val_loss: 0.7401 - val_accuracy: 0.6333\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6786 - accuracy: 0.7250 - val_loss: 0.7386 - val_accuracy: 0.6333\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6773 - accuracy: 0.7250 - val_loss: 0.7371 - val_accuracy: 0.6333\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6760 - accuracy: 0.7250 - val_loss: 0.7356 - val_accuracy: 0.6333\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6747 - accuracy: 0.7250 - val_loss: 0.7341 - val_accuracy: 0.6333\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6734 - accuracy: 0.7250 - val_loss: 0.7325 - val_accuracy: 0.6333\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6720 - accuracy: 0.7250 - val_loss: 0.7311 - val_accuracy: 0.6667\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6707 - accuracy: 0.7250 - val_loss: 0.7297 - val_accuracy: 0.6667\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6694 - accuracy: 0.7250 - val_loss: 0.7283 - val_accuracy: 0.6667\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6681 - accuracy: 0.7250 - val_loss: 0.7268 - val_accuracy: 0.6667\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6668 - accuracy: 0.7250 - val_loss: 0.7253 - val_accuracy: 0.6667\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6654 - accuracy: 0.7333 - val_loss: 0.7239 - val_accuracy: 0.6667\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6641 - accuracy: 0.7333 - val_loss: 0.7225 - val_accuracy: 0.6667\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6629 - accuracy: 0.7333 - val_loss: 0.7210 - val_accuracy: 0.6667\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6616 - accuracy: 0.7333 - val_loss: 0.7196 - val_accuracy: 0.6667\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6602 - accuracy: 0.7417 - val_loss: 0.7182 - val_accuracy: 0.6667\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6589 - accuracy: 0.7417 - val_loss: 0.7167 - val_accuracy: 0.6667\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6576 - accuracy: 0.7417 - val_loss: 0.7152 - val_accuracy: 0.6667\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6564 - accuracy: 0.7417 - val_loss: 0.7138 - val_accuracy: 0.6667\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6551 - accuracy: 0.7417 - val_loss: 0.7123 - val_accuracy: 0.6667\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6538 - accuracy: 0.7417 - val_loss: 0.7110 - val_accuracy: 0.6667\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6525 - accuracy: 0.7417 - val_loss: 0.7096 - val_accuracy: 0.6667\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6512 - accuracy: 0.7417 - val_loss: 0.7082 - val_accuracy: 0.6667\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6500 - accuracy: 0.7417 - val_loss: 0.7068 - val_accuracy: 0.6667\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6487 - accuracy: 0.7417 - val_loss: 0.7055 - val_accuracy: 0.6667\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6475 - accuracy: 0.7417 - val_loss: 0.7041 - val_accuracy: 0.6667\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6462 - accuracy: 0.7417 - val_loss: 0.7026 - val_accuracy: 0.6667\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6450 - accuracy: 0.7417 - val_loss: 0.7012 - val_accuracy: 0.6667\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6437 - accuracy: 0.7417 - val_loss: 0.6998 - val_accuracy: 0.6667\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6424 - accuracy: 0.7417 - val_loss: 0.6984 - val_accuracy: 0.6667\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6412 - accuracy: 0.7417 - val_loss: 0.6970 - val_accuracy: 0.6667\n",
      "Epoch 233/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6400 - accuracy: 0.7417 - val_loss: 0.6956 - val_accuracy: 0.6667\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6388 - accuracy: 0.7417 - val_loss: 0.6942 - val_accuracy: 0.6667\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6375 - accuracy: 0.7417 - val_loss: 0.6928 - val_accuracy: 0.6667\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6363 - accuracy: 0.7417 - val_loss: 0.6914 - val_accuracy: 0.6667\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6350 - accuracy: 0.7417 - val_loss: 0.6901 - val_accuracy: 0.6667\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6338 - accuracy: 0.7417 - val_loss: 0.6888 - val_accuracy: 0.6667\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6326 - accuracy: 0.7417 - val_loss: 0.6874 - val_accuracy: 0.6667\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6314 - accuracy: 0.7417 - val_loss: 0.6861 - val_accuracy: 0.6667\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6302 - accuracy: 0.7417 - val_loss: 0.6848 - val_accuracy: 0.6667\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6290 - accuracy: 0.7417 - val_loss: 0.6834 - val_accuracy: 0.6667\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6278 - accuracy: 0.7417 - val_loss: 0.6822 - val_accuracy: 0.6667\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6266 - accuracy: 0.7417 - val_loss: 0.6808 - val_accuracy: 0.6667\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6255 - accuracy: 0.7417 - val_loss: 0.6794 - val_accuracy: 0.6667\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6242 - accuracy: 0.7417 - val_loss: 0.6781 - val_accuracy: 0.6667\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6230 - accuracy: 0.7417 - val_loss: 0.6769 - val_accuracy: 0.6667\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6218 - accuracy: 0.7417 - val_loss: 0.6756 - val_accuracy: 0.6667\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6206 - accuracy: 0.7417 - val_loss: 0.6743 - val_accuracy: 0.6667\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6195 - accuracy: 0.7417 - val_loss: 0.6731 - val_accuracy: 0.6667\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6184 - accuracy: 0.7417 - val_loss: 0.6719 - val_accuracy: 0.6667\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6171 - accuracy: 0.7500 - val_loss: 0.6704 - val_accuracy: 0.6667\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6159 - accuracy: 0.7500 - val_loss: 0.6690 - val_accuracy: 0.6667\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6148 - accuracy: 0.7500 - val_loss: 0.6676 - val_accuracy: 0.6667\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6135 - accuracy: 0.7500 - val_loss: 0.6663 - val_accuracy: 0.6667\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6125 - accuracy: 0.7500 - val_loss: 0.6649 - val_accuracy: 0.6667\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6112 - accuracy: 0.7583 - val_loss: 0.6636 - val_accuracy: 0.6667\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6101 - accuracy: 0.7583 - val_loss: 0.6623 - val_accuracy: 0.6667\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6089 - accuracy: 0.7583 - val_loss: 0.6611 - val_accuracy: 0.6667\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6078 - accuracy: 0.7583 - val_loss: 0.6597 - val_accuracy: 0.6667\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6067 - accuracy: 0.7583 - val_loss: 0.6586 - val_accuracy: 0.6667\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6055 - accuracy: 0.7583 - val_loss: 0.6572 - val_accuracy: 0.7000\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6044 - accuracy: 0.7583 - val_loss: 0.6559 - val_accuracy: 0.7000\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6032 - accuracy: 0.7583 - val_loss: 0.6547 - val_accuracy: 0.7000\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6021 - accuracy: 0.7583 - val_loss: 0.6534 - val_accuracy: 0.7000\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6010 - accuracy: 0.7583 - val_loss: 0.6521 - val_accuracy: 0.7000\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5999 - accuracy: 0.7667 - val_loss: 0.6509 - val_accuracy: 0.7000\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5987 - accuracy: 0.7667 - val_loss: 0.6497 - val_accuracy: 0.7000\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5976 - accuracy: 0.7667 - val_loss: 0.6484 - val_accuracy: 0.7000\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5966 - accuracy: 0.7667 - val_loss: 0.6471 - val_accuracy: 0.7000\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5953 - accuracy: 0.7667 - val_loss: 0.6460 - val_accuracy: 0.7000\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5943 - accuracy: 0.7667 - val_loss: 0.6447 - val_accuracy: 0.7000\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5932 - accuracy: 0.7667 - val_loss: 0.6434 - val_accuracy: 0.7000\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5921 - accuracy: 0.7667 - val_loss: 0.6422 - val_accuracy: 0.7000\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5910 - accuracy: 0.7667 - val_loss: 0.6412 - val_accuracy: 0.7000\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5899 - accuracy: 0.7667 - val_loss: 0.6398 - val_accuracy: 0.7000\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5888 - accuracy: 0.7667 - val_loss: 0.6386 - val_accuracy: 0.7000\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5877 - accuracy: 0.7667 - val_loss: 0.6374 - val_accuracy: 0.7000\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5866 - accuracy: 0.7667 - val_loss: 0.6363 - val_accuracy: 0.7000\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5855 - accuracy: 0.7667 - val_loss: 0.6351 - val_accuracy: 0.7000\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5845 - accuracy: 0.7667 - val_loss: 0.6339 - val_accuracy: 0.7000\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5834 - accuracy: 0.7667 - val_loss: 0.6327 - val_accuracy: 0.7000\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5822 - accuracy: 0.7667 - val_loss: 0.6314 - val_accuracy: 0.7333\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5812 - accuracy: 0.7750 - val_loss: 0.6301 - val_accuracy: 0.7333\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5801 - accuracy: 0.7750 - val_loss: 0.6289 - val_accuracy: 0.7333\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5791 - accuracy: 0.7750 - val_loss: 0.6277 - val_accuracy: 0.7333\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5781 - accuracy: 0.7750 - val_loss: 0.6264 - val_accuracy: 0.7333\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5769 - accuracy: 0.7833 - val_loss: 0.6252 - val_accuracy: 0.7667\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5759 - accuracy: 0.7833 - val_loss: 0.6240 - val_accuracy: 0.7667\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5749 - accuracy: 0.7833 - val_loss: 0.6229 - val_accuracy: 0.7667\n",
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5737 - accuracy: 0.7833 - val_loss: 0.6217 - val_accuracy: 0.7667\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5727 - accuracy: 0.7833 - val_loss: 0.6204 - val_accuracy: 0.7667\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5717 - accuracy: 0.7833 - val_loss: 0.6192 - val_accuracy: 0.7667\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5707 - accuracy: 0.7833 - val_loss: 0.6181 - val_accuracy: 0.7667\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5696 - accuracy: 0.7833 - val_loss: 0.6168 - val_accuracy: 0.7667\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5685 - accuracy: 0.7917 - val_loss: 0.6156 - val_accuracy: 0.7667\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5676 - accuracy: 0.7917 - val_loss: 0.6145 - val_accuracy: 0.7667\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5664 - accuracy: 0.7917 - val_loss: 0.6133 - val_accuracy: 0.7667\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5654 - accuracy: 0.7917 - val_loss: 0.6122 - val_accuracy: 0.7667\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5644 - accuracy: 0.7917 - val_loss: 0.6111 - val_accuracy: 0.7667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eb8463bdc0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train,y_train,epochs=300,validation_data=(scaled_X_test,y_test),\n",
    "          callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.223007</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.381262</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.205895</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.361450</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.189138</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.342421</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.172733</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.324033</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.158083</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.306110</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  1.223007      0.35  1.381262      0.266667\n",
       "1  1.205895      0.35  1.361450      0.266667\n",
       "2  1.189138      0.35  1.342421      0.266667\n",
       "3  1.172733      0.35  1.324033      0.266667\n",
       "4  1.158083      0.35  1.306110      0.266667"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6110807061195374, 0.7666666507720947]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=0) # final loss and accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the purpose of real world deployment, we train on the entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 1.1175 - accuracy: 0.3333\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 1.1106 - accuracy: 0.3333\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 501us/step - loss: 1.1035 - accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 502us/step - loss: 1.0965 - accuracy: 0.3333\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 1.0903 - accuracy: 0.3333\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0839 - accuracy: 0.3333\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 1.0776 - accuracy: 0.3333\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0713 - accuracy: 0.3333\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 1.0655 - accuracy: 0.3333\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 1.0595 - accuracy: 0.3333\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 1.0539 - accuracy: 0.3333\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 754us/step - loss: 1.0484 - accuracy: 0.3333\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 1.0430 - accuracy: 0.3333\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 751us/step - loss: 1.0377 - accuracy: 0.3333\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 1.0327 - accuracy: 0.3333\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0281 - accuracy: 0.3333\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 1.0228 - accuracy: 0.3333\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0184 - accuracy: 0.3333\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 1.0141 - accuracy: 0.3333\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 1.0096 - accuracy: 0.3333\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 1.0055 - accuracy: 0.3333\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 1.0014 - accuracy: 0.3333\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 501us/step - loss: 0.9974 - accuracy: 0.3333\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9935 - accuracy: 0.3333\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9898 - accuracy: 0.3333\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9862 - accuracy: 0.3333\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 902us/step - loss: 0.9824 - accuracy: 0.3333\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 749us/step - loss: 0.9790 - accuracy: 0.3333\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9755 - accuracy: 0.3333\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9722 - accuracy: 0.3533\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9690 - accuracy: 0.3733\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9657 - accuracy: 0.3733\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9625 - accuracy: 0.3800\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9594 - accuracy: 0.3933\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9563 - accuracy: 0.4067\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9532 - accuracy: 0.4067\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9502 - accuracy: 0.4133\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9473 - accuracy: 0.4400\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9445 - accuracy: 0.4467\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9416 - accuracy: 0.4600\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9388 - accuracy: 0.4800\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9360 - accuracy: 0.4867\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9332 - accuracy: 0.5000\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9304 - accuracy: 0.5133\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9277 - accuracy: 0.5267\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9249 - accuracy: 0.5400\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9222 - accuracy: 0.5600\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9195 - accuracy: 0.5667\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9168 - accuracy: 0.5733\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9142 - accuracy: 0.5867\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9115 - accuracy: 0.5867\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9089 - accuracy: 0.6000\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9062 - accuracy: 0.6133\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.9037 - accuracy: 0.6133\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9012 - accuracy: 0.6133\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 751us/step - loss: 0.8985 - accuracy: 0.6333\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8959 - accuracy: 0.6400\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8933 - accuracy: 0.6467\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 751us/step - loss: 0.8907 - accuracy: 0.6467\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8882 - accuracy: 0.6467\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8857 - accuracy: 0.6600\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8831 - accuracy: 0.6667\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8805 - accuracy: 0.6667\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8780 - accuracy: 0.6667\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8755 - accuracy: 0.6733\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8730 - accuracy: 0.6800\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8705 - accuracy: 0.6800\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8680 - accuracy: 0.6800\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 707us/step - loss: 0.8656 - accuracy: 0.6800\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8631 - accuracy: 0.6867\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8607 - accuracy: 0.6867\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8583 - accuracy: 0.6867\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8559 - accuracy: 0.6867\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8535 - accuracy: 0.6867\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8510 - accuracy: 0.6867\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8486 - accuracy: 0.6867\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8463 - accuracy: 0.6867\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8439 - accuracy: 0.6867\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8415 - accuracy: 0.6867\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8391 - accuracy: 0.6867\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8368 - accuracy: 0.6867\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8344 - accuracy: 0.6867\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8321 - accuracy: 0.6867\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8297 - accuracy: 0.6867\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 501us/step - loss: 0.8274 - accuracy: 0.6867\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8250 - accuracy: 0.6867\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8227 - accuracy: 0.6867\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8204 - accuracy: 0.6867\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8181 - accuracy: 0.6867\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8157 - accuracy: 0.6867\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8134 - accuracy: 0.6867\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8111 - accuracy: 0.6933\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 735us/step - loss: 0.8088 - accuracy: 0.6933\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8065 - accuracy: 0.6933\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.8043 - accuracy: 0.6933\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8020 - accuracy: 0.6933\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7997 - accuracy: 0.6933\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7975 - accuracy: 0.6933\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7952 - accuracy: 0.6933\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7930 - accuracy: 0.6933\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7907 - accuracy: 0.6933\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7885 - accuracy: 0.6933\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7863 - accuracy: 0.6933\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7841 - accuracy: 0.6933\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7819 - accuracy: 0.6933\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7797 - accuracy: 0.6933\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7775 - accuracy: 0.6933\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7754 - accuracy: 0.6933\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7733 - accuracy: 0.6933\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7711 - accuracy: 0.6933\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7689 - accuracy: 0.6933\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7668 - accuracy: 0.6933\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 751us/step - loss: 0.7647 - accuracy: 0.6933\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7626 - accuracy: 0.6933\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7605 - accuracy: 0.6933\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7585 - accuracy: 0.6933\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7563 - accuracy: 0.6933\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7542 - accuracy: 0.6933\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 501us/step - loss: 0.7522 - accuracy: 0.6933\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7502 - accuracy: 0.6933\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7482 - accuracy: 0.6933\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7460 - accuracy: 0.6933\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7440 - accuracy: 0.6933\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7421 - accuracy: 0.6933\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7401 - accuracy: 0.6933\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7380 - accuracy: 0.6933\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7361 - accuracy: 0.7000\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7341 - accuracy: 0.7000\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7321 - accuracy: 0.7000\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7301 - accuracy: 0.7067\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7282 - accuracy: 0.7067\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7263 - accuracy: 0.7067\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7243 - accuracy: 0.7067\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7224 - accuracy: 0.7067\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7205 - accuracy: 0.7067\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7186 - accuracy: 0.7067\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7167 - accuracy: 0.7067\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7148 - accuracy: 0.7067\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7129 - accuracy: 0.7067\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7111 - accuracy: 0.7067\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7092 - accuracy: 0.7067\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7073 - accuracy: 0.7067\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7055 - accuracy: 0.7067\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7036 - accuracy: 0.7067\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.7018 - accuracy: 0.7067\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6999 - accuracy: 0.7067\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 501us/step - loss: 0.6982 - accuracy: 0.7067\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.7067\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6945 - accuracy: 0.7067\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6927 - accuracy: 0.7133\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 751us/step - loss: 0.6909 - accuracy: 0.7200\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6891 - accuracy: 0.7200\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 501us/step - loss: 0.6873 - accuracy: 0.7200\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6854 - accuracy: 0.7200\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6837 - accuracy: 0.7200\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6818 - accuracy: 0.7200\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6800 - accuracy: 0.7200\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 501us/step - loss: 0.6781 - accuracy: 0.7200\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6763 - accuracy: 0.7200\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6744 - accuracy: 0.7200\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6725 - accuracy: 0.7200\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6706 - accuracy: 0.7267\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6687 - accuracy: 0.7267\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 501us/step - loss: 0.6669 - accuracy: 0.7267\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.7267\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6634 - accuracy: 0.7267\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6617 - accuracy: 0.7267\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6599 - accuracy: 0.7267\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6582 - accuracy: 0.7267\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6564 - accuracy: 0.7267\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6547 - accuracy: 0.7267\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.7267\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.7333\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.7333\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6479 - accuracy: 0.7333\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 812us/step - loss: 0.6462 - accuracy: 0.7333\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6445 - accuracy: 0.7333\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6427 - accuracy: 0.7333\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.7333\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6393 - accuracy: 0.7333\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6377 - accuracy: 0.7400\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6360 - accuracy: 0.7400\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.7400\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6327 - accuracy: 0.7467\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6310 - accuracy: 0.7467\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6293 - accuracy: 0.7467\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.7533\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 502us/step - loss: 0.6260 - accuracy: 0.7533\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6244 - accuracy: 0.7533\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6227 - accuracy: 0.7533\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6210 - accuracy: 0.7533\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6194 - accuracy: 0.7533\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6177 - accuracy: 0.7600\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 948us/step - loss: 0.6161 - accuracy: 0.7600\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6145 - accuracy: 0.7600\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6128 - accuracy: 0.7667\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6111 - accuracy: 0.7667\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6095 - accuracy: 0.7667\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6079 - accuracy: 0.7667\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6062 - accuracy: 0.7667\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6045 - accuracy: 0.7667\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.6029 - accuracy: 0.7667\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6013 - accuracy: 0.7667\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.5996 - accuracy: 0.7667\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5980 - accuracy: 0.7667\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5965 - accuracy: 0.7667\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5947 - accuracy: 0.7733\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.7733\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5916 - accuracy: 0.7733\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5899 - accuracy: 0.7733\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 928us/step - loss: 0.5884 - accuracy: 0.7733\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5868 - accuracy: 0.7800\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5852 - accuracy: 0.7800\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5835 - accuracy: 0.7867\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5820 - accuracy: 0.7800\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5804 - accuracy: 0.7867\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5788 - accuracy: 0.7867\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5773 - accuracy: 0.7867\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5757 - accuracy: 0.7867\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5741 - accuracy: 0.7933\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.7867\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5709 - accuracy: 0.7933\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.7933\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 729us/step - loss: 0.5677 - accuracy: 0.7933\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5661 - accuracy: 0.7933\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7933\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5631 - accuracy: 0.8000\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.8000\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 911us/step - loss: 0.5598 - accuracy: 0.8000\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5582 - accuracy: 0.8067\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.8067\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5550 - accuracy: 0.8133\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.8133\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5519 - accuracy: 0.8133\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5504 - accuracy: 0.8200\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5488 - accuracy: 0.8200\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5472 - accuracy: 0.8333\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5456 - accuracy: 0.8400\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5440 - accuracy: 0.8400\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.8400\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5409 - accuracy: 0.8400\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.8400\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.8400\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5365 - accuracy: 0.8400\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5347 - accuracy: 0.8400\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5332 - accuracy: 0.8400\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5316 - accuracy: 0.8400\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5301 - accuracy: 0.8467\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5285 - accuracy: 0.8467\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5270 - accuracy: 0.8467\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5254 - accuracy: 0.8533\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5240 - accuracy: 0.8533\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.8533\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.8600\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5195 - accuracy: 0.8667\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5179 - accuracy: 0.8733\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.8733\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5150 - accuracy: 0.8733\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.8733\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.8733\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.8733\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5088 - accuracy: 0.8800\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 751us/step - loss: 0.5076 - accuracy: 0.8867\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5058 - accuracy: 0.8867\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.8867\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5029 - accuracy: 0.8867\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.5015 - accuracy: 0.8933\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.8933\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.8933\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.8933\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.8933\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.9000\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.9000\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.9067\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.9067\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.9067\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.4871 - accuracy: 0.9067\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.4856 - accuracy: 0.9000\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.4843 - accuracy: 0.9000\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 501us/step - loss: 0.4829 - accuracy: 0.9000\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.4814 - accuracy: 0.9067\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.9067\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.4786 - accuracy: 0.9067\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.4772 - accuracy: 0.9133\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.4758 - accuracy: 0.9133\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.4744 - accuracy: 0.9133\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.4731 - accuracy: 0.9133\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 709us/step - loss: 0.4717 - accuracy: 0.9200\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 501us/step - loss: 0.4703 - accuracy: 0.9200\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.4690 - accuracy: 0.9200\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 784us/step - loss: 0.4676 - accuracy: 0.9200\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.9200\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.9200\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.4637 - accuracy: 0.9133\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.4623 - accuracy: 0.9133\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.4610 - accuracy: 0.9200\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.9200\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.9200\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.9267\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.9267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eb888a4100>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X,y,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"iris_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the scaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model('./iris_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_scaler = joblib.load('./iris_scaler.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_json = {\n",
    "    \"sepal_length\":5.1,\n",
    "    \"sepal_width\":3.5,\n",
    "    \"petal_width\":1.4,\n",
    "    \"petal_length\":0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model,scaler,sample_json):\n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "\n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "\n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    classes_array = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    class_ind =  np.argmax(model.predict(flower))\n",
    "\n",
    "    return classes_array[class_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n",
      "setosa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\viren\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(return_prediction(flower_model,flower_scaler,sample_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model('./iris_final.h5')\n",
    "flower_scaler = joblib.load('./iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model,scaler,sample_json):\n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "\n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "\n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    classes_array = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    class_ind =  np.argmax(model.predict(flower))\n",
    "\n",
    "    return classes_array[class_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
